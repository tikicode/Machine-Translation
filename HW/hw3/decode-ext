#!/usr/bin/env python
import optparse
import sys
import models
import numpy
from collections import namedtuple
from math import log
import random

optparser = optparse.OptionParser()
optparser.add_option("-i", "--input", dest="input", default="data/input", help="File containing sentences to translate (default=data/input)")
optparser.add_option("-t", "--translation-model", dest="tm", default="data/tm", help="File containing translation model (default=data/tm)")
optparser.add_option("-l", "--language-model", dest="lm", default="data/lm", help="File containing ARPA-format language model (default=data/lm)")
optparser.add_option("-n", "--num_sentences", dest="num_sents", default=sys.maxsize,
                     type="int", help="Number of sentences to decode (default=no limit)")
optparser.add_option("-k", "--translations-per-phrase", dest="k", default=10, type="int",
                     help="Limit on number of translations to consider per phrase (default=1)")
optparser.add_option("-s", "--stack-size", dest="s", default=100, type="int", help="Maximum stack size (default=1)")
optparser.add_option("-d", "--distort", dest="d", default=6, help="Distortion limit (def. 6)")
optparser.add_option("-v", "--verbose", dest="verbose", action="store_true", default=False, help="Verbose mode (default=off)")
opts, _ = optparser.parse_args()

tm = models.TM(opts.tm, opts.k)
lm = models.LM(opts.lm)
french = [tuple(line.strip().split()) for line in open(opts.input).readlines()[:opts.num_sents]]
costs = None  # Matrix of future costs estimates. This should be initialized per sentence.

# returns the length of the english translation in h
# corresponds to the value r in collins' paper on decoding
def calculate_r(h):
    if h is None:
        return 0
    
    predecessor_r = calculate_r(h.predecessor)
    phrase_length = len(h.phrase.english.split()) if h.phrase else 0
    
    return predecessor_r + phrase_length

tm.update({(word,): [models.phrase(word, 0.0)] for word in set(sum(french, ())) if (word,) not in tm})


def constructFutureCosts(f):
    minProb = -500
    sentenceLength = len(f)
    # Initialize the costs matrix with a large value
    costs = numpy.full((sentenceLength, sentenceLength), minProb)

    for col in range(sentenceLength):
        for row in range(sentenceLength - col):
            start = row
            end = row + col + 1

            # Extract the French phrase for convenience
            french_phrase = f[start:end]

            # Calculate the best estimate based on available phrases in the translation model
            if french_phrase in tm:
                best_estimate = max(phrase.logprob for phrase in tm[french_phrase])
            else:
                best_estimate = minProb

            costs[row, col] = best_estimate

            for i in range(col):
                candidate_cost = costs[row, col - i - 1] + costs[row + col - i, i]
                costs[row, col] = max(costs[row, col], candidate_cost)

    return costs
    

def getFutureCostForHypothesis(hypothesis, f, start, end):
    # Find out what words have been translated by up to this hypothesis
    translated = numpy.zeros(len(f))
    translated[start:end] = 1

    prevHypothesis = hypothesis
    while prevHypothesis is not None:
        translated[prevHypothesis.phraseStart:prevHypothesis.phraseEnd] = 1
        prevHypothesis = prevHypothesis.predecessor

    # Calculate the future cost using a more Pythonic approach
    futureCost = 0
    untranslated_chunk = []

    for i in range(len(f)):
        if translated[i] == 0:  # Word location marked as untranslated.
            untranslated_chunk.append(i)
        else:
            if untranslated_chunk:
                start = untranslated_chunk[0]
                end = untranslated_chunk[-1] + 1
                futureCost += costs[start, end - 1]
                untranslated_chunk = []

    # Handle the last untranslated chunk, if any
    if untranslated_chunk:
        start = untranslated_chunk[0]
        end = untranslated_chunk[-1] + 1
        futureCost += costs[start, end - 1]

    return futureCost
    

# Follow predecessor pointers back to find the hypothesis at a given depth
def getHypothesis(h, to_modify):
    h_ = h
    child = None
    for j in range(to_modify):
        child = h_
        h_ = h_.predecessor
    return (h_, child)

# Given a list of phrases, constructs a new hypothesis where all those
# phrases are translated in the order they were passed to this function.
def create_hypothesis(h, at_end, phrases, f):
    logprob = h.logprob
    lm_state = h.lm_state
    last_hypothesis = h
    for phrase, (start, end) in phrases:  # At most two phrases.
        logprob += phrase.logprob
        for word in phrase.english.split():
            (lm_state, word_logprob) = lm.score(lm_state, word)
            logprob += word_logprob
        if phrase == phrases[-1]:  # Add the "</s>" if this is the last phrase in the sentence.
            logprob += lm.end(lm_state) if at_end else 0.0

        # Calculate the future cost.
        futureCost = getFutureCostForHypothesis(h, f, start, end)

        # distortion, such as it is
        logprob += 0 if abs(calculate_r(h) - start + 1) <= int(opts.d) else -10 * abs(calculate_r(h) + 1 - start)

        new_hypothesis = hypothesis(logprob, lm_state, last_hypothesis, phrase, start, end, futureCost,
                                    [v if (i < start or i >= end) else 1 for (i, v) in enumerate(last_hypothesis.coverage)])
        last_hypothesis = new_hypothesis
    return (lm_state, new_hypothesis)

sys.stderr.write("Decoding %s...\n" % (opts.input,))



for f in french:
    # Construct the best future cost estimate table.
    costs = constructFutureCosts(f)

    sys.stderr.write("Working on sentence: %s\n" % (f,))

    hypothesis = namedtuple("hypothesis", "logprob, lm_state, predecessor, phrase, phraseStart, phraseEnd, futureCost, coverage")
    initial_hypothesis = hypothesis(0.0, lm.begin(), None, None, -1, -1, 0, [0 for i in range(len(f))])
    stacks = [{} for _ in f] + [{}]  # stacks[i] holds hypotheses with i words decoded
    stacks[0][lm.begin()] = initial_hypothesis
    for i, stack in enumerate(stacks[:-1]):
        for h in sorted(stack.values(), key=lambda h: -(h.logprob + h.futureCost))[:opts.s]:  # prune # take best opts.s entries in the stack
            for start in range(len(f)):
                for end in range(start + 1, len(f) + 1):
                    if sum(h.coverage[start:end]) == 0:  # if this span is not covered
                        if f[start:end] in tm:
                            for phrase in tm[f[start:end]]:
                                (lm_state, new_hypothesis) = create_hypothesis(h, (sum(h.coverage) + (end - start)) == len(f), [(phrase, (start, end))], f)
                                covered = sum(new_hypothesis.coverage)
                                if (h.coverage.index(0) == start or f[h.coverage.index(0):start] in tm) and (
                                        lm_state not in stacks[covered] or stacks[covered][lm_state].logprob < new_hypothesis.logprob):  # second case is recombination
                                    stacks[covered][lm_state] = new_hypothesis
    winner = max(stacks[-1].values(), key=lambda h: h.logprob)

    def extract_english(h):
        return "" if h.predecessor is None else "%s%s " % (extract_english(h.predecessor), h.phrase.english)

    print(extract_english(winner))
    if opts.verbose:
        def extract_tm_logprob(h):
            return 0.0 if h.predecessor is None else h.phrase.logprob + extract_tm_logprob(h.predecessor)
        tm_logprob = extract_tm_logprob(winner)
        sys.stderr.write("LM = %f, TM = %f, Total = %f\n" %
                         (winner.logprob - tm_logprob, tm_logprob, winner.logprob))

       



    